{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import yaml\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "args_file = \"./args.yaml\"\n",
    "\n",
    "with open(args_file) as f:\n",
    "    args_dict = yaml.load(f)\n",
    "\n",
    "extra_args_file = \"\"\n",
    "    \n",
    "if extra_args_file:\n",
    "    with open(extra_args_file) as f:\n",
    "        extra_args_dict = yaml.load(f)\n",
    "        for k,v in extra_args_dict.items():\n",
    "            args_dict[k] = v\n",
    "\n",
    "args = Dict2Obj(args_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_dir = \"./output/11May2020-12:22:15/checkpoint-915\"\n",
    "checkpoint_dir = \"./output/15May2020-14:47:51/checkpoint-198\"\n",
    "args['model_name_or_path'] = checkpoint_dir\n",
    "args['config_name'] = checkpoint_dir\n",
    "args['tokenizer_name'] = checkpoint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_system = BertNerSystem(args)  # Load model\n",
    "trainer = get_trainer(ner_system, args)  # get the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertNerSystem(\n",
       "  (model): BertForTokenClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 1024)\n",
       "        (token_type_embeddings): Embedding(2, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (12): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (13): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (14): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (15): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (16): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (17): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (18): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (19): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (20): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (21): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (22): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (23): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_system.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test data: 100%|██████████| 543/543 [00:04<00:00, 132.15it/s]\n",
      "Loading test data: 100%|██████████| 543/543 [00:04<00:00, 135.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 231/231 [00:19<00:00, 11.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils:***** Test results *****\n",
      "INFO:utils:exact_nonpositional = 0.757\n",
      "\n",
      "INFO:utils:exact_subtoken = 0.443\n",
      "\n",
      "INFO:utils:exact_token = 0.454\n",
      "\n",
      "INFO:utils:partial_nonpositional = 0.795\n",
      "\n",
      "INFO:utils:partial_subtoken = 0.485\n",
      "\n",
      "INFO:utils:partial_token = 0.488\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'exact_nonpositional': 0.7566607460035524,\n",
      " 'exact_subtoken': 0.44268292682926824,\n",
      " 'exact_token': 0.45383222691611347,\n",
      " 'partial_nonpositional': 0.7952167414050823,\n",
      " 'partial_subtoken': 0.48536036036036034,\n",
      " 'partial_token': 0.48783248443689875}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 231/231 [00:20<00:00, 11.41it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.test(ner_system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val data: 100%|██████████| 543/543 [00:04<00:00, 133.81it/s]\n"
     ]
    }
   ],
   "source": [
    "val_dataset = BertNerDataset(\n",
    "    ner_system.tokenizer, data_path=args.val_data_path, type_path=\"val\", \\\n",
    "    doc_size=args.doc_max_seq_length, batch_size=args.eval_batch_size\n",
    ")\n",
    "dataloader = DataLoader(val_dataset, batch_size=args.eval_batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = list(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BertNerSystem.test_step of BertNerSystem(\n",
       "  (model): BertForTokenClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 1024)\n",
       "        (token_type_embeddings): Embedding(2, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (12): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (13): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (14): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (15): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (16): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (17): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (18): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (19): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (20): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (21): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (22): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (23): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_system.test_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'an', 'chronic myelomonocytic leukemia', 'myelodysplastic syndromes'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = batches[15]\n",
    "\n",
    "outputs, = ner_system.forward(input_ids=batch['tokens'].to('cuda:0'), attention_mask=batch[\"attention_mask\"].to('cuda:0'))\n",
    "iob_predictions = torch.argmax(outputs, dim=2)\n",
    "\n",
    "iob_predictions = iob_predictions.squeeze(dim=0).tolist()[0]\n",
    "tokens = batch['tokens'].squeeze(dim=0).tolist()[0]\n",
    "\n",
    "predictions = set()\n",
    "words = \"\"\n",
    "for i,p in enumerate(iob_predictions):\n",
    "    if tokens[i] == 0: continue\n",
    "    if p == 0: continue\n",
    "    if p == 1: \n",
    "        predictions.add(str(words[1:]))\n",
    "        words = \"\"\n",
    "    \n",
    "    sub_token = vocab[tokens[i]]\n",
    "    if sub_token[:2] == '##':\n",
    "        sub_token = sub_token[2:]\n",
    "    else:\n",
    "        sub_token = ' ' + sub_token\n",
    "    words += sub_token\n",
    "else:    \n",
    "    if len(words):\n",
    "        predictions.add(str(words[1:]))\n",
    "\n",
    "if \"\" in predictions:\n",
    "    predictions.remove(\"\")\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7c833f59944f399ed774a2e11c2e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=462.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for batch in tqdm(batches):\n",
    "    outputs, = ner_system.forward(input_ids=batch['tokens'].to('cuda:0'), attention_mask=batch[\"attention_mask\"].to('cuda:0'))\n",
    "    batch_predictions = torch.argmax(outputs, dim=2)\n",
    "    predictions.append(batch_predictions.squeeze(dim=0).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test metrics\n",
    "\n",
    "Standard metrics:\n",
    "* Exact\n",
    "* Partial (some overlap)\n",
    "\n",
    "Modifications to handle sub-tokenisation:\n",
    "* Token\n",
    "* Sub-token\n",
    "\n",
    "Modificiations to handle multiple mentions:\n",
    "* Positional\n",
    "* Non-positional (retrieve tokens from document and compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "\n",
    "def score_overlap(loc1,loc2):\n",
    "    range1 = set(range(loc1[0],loc1[1]+1))\n",
    "    range2 = set(range(loc2[0],loc2[1]+1))\n",
    "    \n",
    "    if range1 & range2:\n",
    "        if range1 == range2:\n",
    "            return \"exact\"\n",
    "        else:\n",
    "            return \"partial\"\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def get_locs(labels):\n",
    "    locs = []\n",
    "    new_loc = True\n",
    "    loc_range = []\n",
    "    for i,l in enumerate(labels):\n",
    "        if l == 0:\n",
    "            new_loc = True\n",
    "            continue\n",
    "        if l > 0:\n",
    "            if new_loc:\n",
    "                if len(loc_range):\n",
    "                    locs.append((loc_range[0],loc_range[-1]))\n",
    "                loc_range = []\n",
    "                new_loc = False\n",
    "            loc_range.append(i)\n",
    "    \n",
    "    return locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_map = {'exact': 2, 'partial': 1, False: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_i = 5\n",
    "batch = batches[batch_i]\n",
    "prediction = predictions[batch_i]\n",
    "batch_labels = batch['labels'].squeeze(dim=0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predictions_subtoken(predictions, targets, batch, score_map={'exact': 2, 'partial': 1, False: 0}):\n",
    "    prediction_locs = get_locs(predictions)\n",
    "    target_locs = get_locs(targets)\n",
    "    \n",
    "    prediction_matches = {p_loc: False for p_loc in prediction_locs}\n",
    "    target_matches = {t_loc: False for t_loc in target_locs}\n",
    "\n",
    "    for p_loc, t_loc in it.product(prediction_locs, target_locs):\n",
    "        score = score_overlap(p_loc,t_loc)\n",
    "        if score_map[score] > score_map[prediction_matches[p_loc]]:\n",
    "            prediction_matches[p_loc] = score\n",
    "        if score_map[score] > score_map[target_matches[t_loc]]:\n",
    "            target_matches[t_loc] = score\n",
    "            \n",
    "    exacts = len([k for k,v in target_matches.items() if v == 'exact'])\n",
    "    partials = len([k for k,v in target_matches.items() if v == 'partial'])\n",
    "    misses = len([k for k,v in target_matches.items() if v == False])\n",
    "    spurious = len([k for k,v in prediction_matches.items() if v == False])\n",
    "    \n",
    "    return exacts, partials, misses, spurious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(tp,fn,fp):\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return {'precision': precision, 'recall': recall, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-bbcd15927ef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexacts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmisses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspurious\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexacts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmisses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspurious\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# exact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpartial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexacts\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpartials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmisses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspurious\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# partial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "exacts, partials, misses, spurious = test_predictions(prediction, batch_labels)\n",
    "exact = get_metrics(exacts,misses,spurious)  # exact\n",
    "partial = get_metrics(exacts+partials,misses,spurious)  # partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.7142857142857143,\n",
       " 'recall': 0.45454545454545453,\n",
       " 'f1': 0.5555555555555556}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.8181818181818182, 'recall': 0.6, 'f1': 0.6923076923076923}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens\n",
    "\n",
    "Barely makes any difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_subtokens(subtokens):\n",
    "    subtoken_map = []\n",
    "    token_i = 0\n",
    "    for t in subtokens:\n",
    "        if not t[:2] == \"##\":\n",
    "            token_i += 1\n",
    "        subtoken_map.append(token_i)\n",
    "\n",
    "    return subtoken_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtokens = [vocab[t] for t in batch['tokens'].squeeze(dim=0).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtoken_map = map_subtokens(subtokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtoken2token_labels(labels, subtoken_map):\n",
    "    token_labels = [0 for i in range(max(subtoken_map)+1)]\n",
    "    for i,t in enumerate(labels):\n",
    "        token_i = subtoken_map[i]\n",
    "        if t > token_labels[token_i]:\n",
    "            token_labels[token_i] = t\n",
    "    return token_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_targets = subtoken2token_labels(batch_labels, subtoken_map)\n",
    "token_predictions = subtoken2token_labels(prediction, subtoken_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "exacts, partials, misses, spurious = test_predictions(token_targets, token_predictions)\n",
    "exact = get_metrics(exacts,misses,spurious)  # exact\n",
    "partial = get_metrics(exacts+partials,misses,spurious)  # partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.45454545454545453,\n",
       " 'recall': 0.7142857142857143,\n",
       " 'f1': 0.5555555555555556}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.6, 'recall': 0.8181818181818182, 'f1': 0.6923076923076923}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predictions_token(predictions, targets, batch, score_map={'exact': 2, 'partial': 1, False: 0}):\n",
    "    subtokens = [vocab[t] for t in batch['tokens'].squeeze(dim=0).tolist()]\n",
    "    subtoken_map = map_subtokens(subtokens)\n",
    "    targets = subtoken2token_labels(targets, subtoken_map)\n",
    "    predictions = subtoken2token_labels(predictions, subtoken_map)\n",
    "    \n",
    "    return test_predictions_subtoken(predictions, targets, batch, score_map=score_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all(predictions, batches, f, f_kwargs={}, token=False):\n",
    "    exacts = 0\n",
    "    partials = 0\n",
    "    misses = 0\n",
    "    spurious = 0\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        batch = batches[i]\n",
    "        prediction = predictions[i]\n",
    "        target = batch['labels'].squeeze(dim=0).tolist()\n",
    "        \n",
    "        batch_exacts, batch_partials, batch_misses, batch_spurious = f(prediction, target, batch, **f_kwargs)\n",
    "        \n",
    "        exacts += batch_exacts\n",
    "        partials += batch_partials\n",
    "        misses += batch_misses\n",
    "        spurious += batch_spurious\n",
    "\n",
    "    exact = get_metrics(exacts,misses,spurious)  # exact\n",
    "    partial = get_metrics(exacts+partials,misses,spurious)  # partial\n",
    "    \n",
    "    return exact, partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact, partial = test_all(predictions, token=False, subtoken_map=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.14462123011161243,\n",
       " 'recall': 0.697594501718213,\n",
       " 'f1': 0.2395751376868607}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.18229284903518728,\n",
       " 'recall': 0.7525773195876289,\n",
       " 'f1': 0.29349415204678364}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact, partial = test_all(predictions, token=True, subtoken_map=subtoken_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.14589886281151707,\n",
       " 'recall': 0.7011627906976744,\n",
       " 'f1': 0.2415381534147807}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.18324849606663582,\n",
       " 'recall': 0.7550047664442326,\n",
       " 'f1': 0.2949171476447589}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-positional\n",
    "\n",
    "This indicates a much higher precision and F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_overlap(s1,s2):\n",
    "    if s1[0] in s2:\n",
    "        for begin_i in [i for i,t in enumerate(s2) if t == s1[0]]:\n",
    "            for s1_i,s2_i in enumerate(range(begin_i,len(s2))):\n",
    "                if s1_i >= len(s1):\n",
    "                    continue\n",
    "                if not s1[s1_i] == s2[s2_i]:\n",
    "                    break\n",
    "            else:\n",
    "                return True\n",
    "            \n",
    "    return False\n",
    "\n",
    "def sequence_overlap_twoway(s1,s2):\n",
    "    if sequence_overlap(s1,s2): \n",
    "        return set(s1) & set(s2)\n",
    "    if sequence_overlap(s2,s1): \n",
    "        return set(s1) & set(s2)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled_tokens(labels, tokens):\n",
    "    labeled_tokens = set()\n",
    "    token_range = []\n",
    "    for i,p in enumerate(labels):\n",
    "        if tokens[i] == 0: continue\n",
    "        if p == 0: continue\n",
    "        if p == 1: \n",
    "            labeled_tokens.add(tuple(token_range[1:]))\n",
    "            token_range = []\n",
    "        token_range.append(tokens[i])\n",
    "    else:    \n",
    "        if len(token_range):\n",
    "            labeled_tokens.add(tuple(token_range[1:]))\n",
    "            \n",
    "    if () in labeled_tokens:\n",
    "        labeled_tokens.remove(())\n",
    "    \n",
    "    return labeled_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predictions_nonpositional(predictions, targets, batch, threshold=0.5):\n",
    "    batch_tokens = batch['tokens'].squeeze(dim=0).tolist()\n",
    "    prediction_tokens = get_labeled_tokens(predictions, batch_tokens)\n",
    "    target_tokens = get_labeled_tokens(targets, batch_tokens)\n",
    "    \n",
    "    prediction_matches = {p_tokens: False for p_tokens in prediction_tokens}\n",
    "    target_matches = {t_tokens: False for t_tokens in target_tokens}\n",
    "\n",
    "    for p_tokens,t_tokens in it.product(prediction_tokens,target_tokens):\n",
    "        overlap = sequence_overlap_twoway(p_tokens,t_tokens)\n",
    "        if overlap:\n",
    "            if ((len(overlap) / len(t_tokens)) > threshold) and ((len(overlap) / len(p_tokens)) > threshold):\n",
    "                if t_tokens == p_tokens:\n",
    "                    prediction_matches[p_tokens] = \"exact\"\n",
    "                    target_matches[t_tokens] = \"exact\"\n",
    "                else:\n",
    "                    prediction_matches[p_tokens] = \"partial\"\n",
    "                    target_matches[t_tokens] = \"partial\"\n",
    "\n",
    "    exacts = len([k for k,v in target_matches.items() if v == 'exact'])\n",
    "    partials = len([k for k,v in target_matches.items() if v == 'partial'])\n",
    "    misses = len([k for k,v in target_matches.items() if v == False])\n",
    "    spurious = len([k for k,v in prediction_matches.items() if v == False])\n",
    "    \n",
    "    return exacts, partials, misses, spurious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact, partial = test_all(predictions, f=test_predictions_nonpositional, f_kwargs={'threshold': 0.33})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.6912568306010929,\n",
       " 'recall': 0.7386861313868613,\n",
       " 'f1': 0.7141848976711361}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.7460674157303371,\n",
       " 'recall': 0.7876631079478055,\n",
       " 'f1': 0.7663012117714946}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different models and checkpoints\n",
    "\n",
    "Bundle the functions together for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import yaml\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_dir, args_fp=\"./args.yaml\"):\n",
    "    with open(args_fp) as f:\n",
    "        args_dict = yaml.load(f)\n",
    "\n",
    "    args = Dict2Obj(args_dict)\n",
    "    \n",
    "    args['model_name_or_path'] = checkpoint_dir\n",
    "    args['config_name'] = checkpoint_dir\n",
    "    args['tokenizer_name'] = checkpoint_dir\n",
    "    \n",
    "    ner_system = BertNerSystem(args)  # Load model\n",
    "    trainer = get_trainer(ner_system, args)  # get the trainer\n",
    "    vocab = {v:k for k,v in ner_system.tokenizer.get_vocab().items()}\n",
    "    ner_system.model.eval()  # stops dropout\n",
    "    ner_system.to('cuda:0')\n",
    "    \n",
    "    return ner_system, trainer, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(ner_system, fp, doc_size=512, batch_size=1):\n",
    "    val_dataset = BertNerDataset(\n",
    "        ner_system.tokenizer, data_path=fp, type_path=\"val\", \\\n",
    "        doc_size=doc_size, batch_size=batch_size\n",
    "    )\n",
    "    dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    return list(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(ner_system, batches):\n",
    "    predictions = []\n",
    "    for batch in tqdm(batches, desc=\"Generating predictions\"):\n",
    "        outputs, = ner_system.forward(input_ids=batch['tokens'].to('cuda:0'), attention_mask=batch[\"attention_mask\"].to('cuda:0'))\n",
    "        batch_predictions = torch.argmax(outputs, dim=2)\n",
    "        predictions.append(batch_predictions.squeeze(dim=0).tolist())\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_test_metrics(predictions, batches):\n",
    "    exact_subtoken, partial_subtoken = test_all(predictions, batches, f=test_predictions_subtoken, f_kwargs={'score_map': {'exact': 2, 'partial': 1, False: 0}})\n",
    "    exact_token, partial_token = test_all(predictions, batches, f=test_predictions_token, f_kwargs={'score_map': {'exact': 2, 'partial': 1, False: 0}})\n",
    "    exact_nonpositional, partial_nonpositional = test_all(predictions, batches, f=test_predictions_nonpositional, f_kwargs={'threshold': 0.33})\n",
    "    return {\n",
    "        'exact_subtoken': exact_subtoken, \n",
    "        'partial_subtoken': partial_subtoken, \n",
    "        'exact_token': exact_token, \n",
    "        'partial_token': partial_token, \n",
    "        'exact_nonpositional': exact_nonpositional, \n",
    "        'partial_nonpositional': partial_nonpositional\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def metrics_table(metrics, metrics_types=['precision', 'recall', 'f1'], metrics_strategies=['exact_subtoken', 'partial_subtoken', 'exact_token', 'partial_token', 'exact_nonpositional', 'partial_nonpositional']):\n",
    "    table = []\n",
    "    for metrics_strategy in metrics_strategies:\n",
    "        metrics_data = metrics[metrics_strategy]\n",
    "        table_row = []\n",
    "        for metrics_type in metrics_types:\n",
    "            table_row.append(metrics_data[metrics_type])\n",
    "        table.append(table_row)\n",
    "\n",
    "    return pd.DataFrame(table, columns=metrics_types, index=metrics_strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val data: 100%|██████████| 543/543 [00:04<00:00, 118.32it/s]\n",
      "Generating predictions: 100%|██████████| 462/462 [00:45<00:00, 10.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exact_subtoken</th>\n",
       "      <td>0.144621</td>\n",
       "      <td>0.697595</td>\n",
       "      <td>0.239575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_subtoken</th>\n",
       "      <td>0.182293</td>\n",
       "      <td>0.752577</td>\n",
       "      <td>0.293494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_token</th>\n",
       "      <td>0.156652</td>\n",
       "      <td>0.714130</td>\n",
       "      <td>0.256942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_token</th>\n",
       "      <td>0.184835</td>\n",
       "      <td>0.753052</td>\n",
       "      <td>0.296817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_nonpositional</th>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.716270</td>\n",
       "      <td>0.684360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_nonpositional</th>\n",
       "      <td>0.723837</td>\n",
       "      <td>0.776911</td>\n",
       "      <td>0.749436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall        f1\n",
       "exact_subtoken          0.144621  0.697595  0.239575\n",
       "partial_subtoken        0.182293  0.752577  0.293494\n",
       "exact_token             0.156652  0.714130  0.256942\n",
       "partial_token           0.184835  0.753052  0.296817\n",
       "exact_nonpositional     0.655172  0.716270  0.684360\n",
       "partial_nonpositional   0.723837  0.776911  0.749436"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = \"./output/11May2020-12:22:15/checkpoint-915\"\n",
    "ner_system, trainer, vocab = load_model(checkpoint_dir, args_fp=\"./args.yaml\")\n",
    "\n",
    "batches = load_test_data(ner_system, \"./data/dev-ner.json\")\n",
    "\n",
    "predictions = generate_predictions(ner_system, batches)\n",
    "\n",
    "metrics = all_test_metrics(predictions, batches)\n",
    "\n",
    "df = metrics_table(metrics)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val data: 100%|██████████| 543/543 [00:04<00:00, 116.34it/s]\n",
      "Generating predictions: 100%|██████████| 462/462 [00:45<00:00, 10.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exact_subtoken</th>\n",
       "      <td>0.150354</td>\n",
       "      <td>0.760358</td>\n",
       "      <td>0.251063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_subtoken</th>\n",
       "      <td>0.181876</td>\n",
       "      <td>0.799438</td>\n",
       "      <td>0.296335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_token</th>\n",
       "      <td>0.159523</td>\n",
       "      <td>0.771368</td>\n",
       "      <td>0.264372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_token</th>\n",
       "      <td>0.182814</td>\n",
       "      <td>0.799061</td>\n",
       "      <td>0.297552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_nonpositional</th>\n",
       "      <td>0.629956</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.684757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_nonpositional</th>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.776911</td>\n",
       "      <td>0.716032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall        f1\n",
       "exact_subtoken          0.150354  0.760358  0.251063\n",
       "partial_subtoken        0.181876  0.799438  0.296335\n",
       "exact_token             0.159523  0.771368  0.264372\n",
       "partial_token           0.182814  0.799061  0.297552\n",
       "exact_nonpositional     0.629956  0.750000  0.684757\n",
       "partial_nonpositional   0.664000  0.776911  0.716032"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = \"./output/11May2020-12:22:15/checkpoint-1830\"\n",
    "ner_system, trainer, vocab = load_model(checkpoint_dir, args_fp=\"./args.yaml\")\n",
    "\n",
    "batches = load_test_data(ner_system, \"./data/dev-ner.json\")\n",
    "\n",
    "predictions = generate_predictions(ner_system, batches)\n",
    "\n",
    "metrics = all_test_metrics(predictions, batches)\n",
    "\n",
    "df = metrics_table(metrics)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val data: 100%|██████████| 543/543 [00:04<00:00, 117.30it/s]\n",
      "Generating predictions: 100%|██████████| 462/462 [00:45<00:00, 10.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exact_subtoken</th>\n",
       "      <td>0.150888</td>\n",
       "      <td>0.743274</td>\n",
       "      <td>0.250851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_subtoken</th>\n",
       "      <td>0.183410</td>\n",
       "      <td>0.785380</td>\n",
       "      <td>0.297374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_token</th>\n",
       "      <td>0.160163</td>\n",
       "      <td>0.755080</td>\n",
       "      <td>0.264271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_token</th>\n",
       "      <td>0.184222</td>\n",
       "      <td>0.784977</td>\n",
       "      <td>0.298412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_nonpositional</th>\n",
       "      <td>0.632530</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.682372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_nonpositional</th>\n",
       "      <td>0.669377</td>\n",
       "      <td>0.770671</td>\n",
       "      <td>0.716461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall        f1\n",
       "exact_subtoken          0.150888  0.743274  0.250851\n",
       "partial_subtoken        0.183410  0.785380  0.297374\n",
       "exact_token             0.160163  0.755080  0.264271\n",
       "partial_token           0.184222  0.784977  0.298412\n",
       "exact_nonpositional     0.632530  0.740741  0.682372\n",
       "partial_nonpositional   0.669377  0.770671  0.716461"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = \"./output/11May2020-12:22:15/checkpoint-2745\"\n",
    "ner_system, trainer, vocab = load_model(checkpoint_dir, args_fp=\"./args.yaml\")\n",
    "\n",
    "batches = load_test_data(ner_system, \"./data/dev-ner.json\")\n",
    "\n",
    "predictions = generate_predictions(ner_system, batches)\n",
    "\n",
    "metrics = all_test_metrics(predictions, batches)\n",
    "\n",
    "df = metrics_table(metrics)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with extra LM pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val data: 100%|██████████| 543/543 [00:04<00:00, 128.59it/s]\n",
      "Generating predictions: 100%|██████████| 462/462 [00:18<00:00, 24.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exact_subtoken</th>\n",
       "      <td>0.308744</td>\n",
       "      <td>0.785037</td>\n",
       "      <td>0.443189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_subtoken</th>\n",
       "      <td>0.340972</td>\n",
       "      <td>0.808810</td>\n",
       "      <td>0.479711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_token</th>\n",
       "      <td>0.315114</td>\n",
       "      <td>0.788601</td>\n",
       "      <td>0.450296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_token</th>\n",
       "      <td>0.342346</td>\n",
       "      <td>0.808451</td>\n",
       "      <td>0.481006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_nonpositional</th>\n",
       "      <td>0.734114</td>\n",
       "      <td>0.814471</td>\n",
       "      <td>0.772208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_nonpositional</th>\n",
       "      <td>0.772857</td>\n",
       "      <td>0.843994</td>\n",
       "      <td>0.806861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall        f1\n",
       "exact_subtoken          0.308744  0.785037  0.443189\n",
       "partial_subtoken        0.340972  0.808810  0.479711\n",
       "exact_token             0.315114  0.788601  0.450296\n",
       "partial_token           0.342346  0.808451  0.481006\n",
       "exact_nonpositional     0.734114  0.814471  0.772208\n",
       "partial_nonpositional   0.772857  0.843994  0.806861"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = \"./output/15May2020-14:47:51/checkpoint-234\"\n",
    "ner_system, trainer, vocab = load_model(checkpoint_dir, args_fp=\"./args.yaml\")\n",
    "\n",
    "batches = load_test_data(ner_system, \"./data/dev-ner.json\")\n",
    "\n",
    "predictions = generate_predictions(ner_system, batches)\n",
    "\n",
    "metrics = all_test_metrics(predictions, batches)\n",
    "\n",
    "df = metrics_table(metrics)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val data: 100%|██████████| 543/543 [00:04<00:00, 135.35it/s]\n",
      "Generating predictions: 100%|██████████| 462/462 [00:18<00:00, 24.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exact_subtoken</th>\n",
       "      <td>0.304903</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>0.439299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_subtoken</th>\n",
       "      <td>0.338950</td>\n",
       "      <td>0.810684</td>\n",
       "      <td>0.478033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_token</th>\n",
       "      <td>0.312243</td>\n",
       "      <td>0.788382</td>\n",
       "      <td>0.447322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_token</th>\n",
       "      <td>0.339645</td>\n",
       "      <td>0.808451</td>\n",
       "      <td>0.478333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_nonpositional</th>\n",
       "      <td>0.726368</td>\n",
       "      <td>0.812616</td>\n",
       "      <td>0.767075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_nonpositional</th>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.842434</td>\n",
       "      <td>0.802377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall        f1\n",
       "exact_subtoken          0.304903  0.785563  0.439299\n",
       "partial_subtoken        0.338950  0.810684  0.478033\n",
       "exact_token             0.312243  0.788382  0.447322\n",
       "partial_token           0.339645  0.808451  0.478333\n",
       "exact_nonpositional     0.726368  0.812616  0.767075\n",
       "partial_nonpositional   0.765957  0.842434  0.802377"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = \"./output/15May2020-14:47:51/checkpoint-288\"\n",
    "ner_system, trainer, vocab = load_model(checkpoint_dir, args_fp=\"./args.yaml\")\n",
    "\n",
    "batches = load_test_data(ner_system, \"./data/dev-ner.json\")\n",
    "\n",
    "predictions = generate_predictions(ner_system, batches)\n",
    "\n",
    "metrics = all_test_metrics(predictions, batches)\n",
    "\n",
    "df = metrics_table(metrics)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val data: 100%|██████████| 543/543 [00:04<00:00, 135.11it/s]\n",
      "Generating predictions: 100%|██████████| 462/462 [00:18<00:00, 24.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exact_subtoken</th>\n",
       "      <td>0.292356</td>\n",
       "      <td>0.790202</td>\n",
       "      <td>0.426805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_subtoken</th>\n",
       "      <td>0.326332</td>\n",
       "      <td>0.815370</td>\n",
       "      <td>0.466113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_token</th>\n",
       "      <td>0.299646</td>\n",
       "      <td>0.792924</td>\n",
       "      <td>0.434932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_token</th>\n",
       "      <td>0.327163</td>\n",
       "      <td>0.813146</td>\n",
       "      <td>0.466595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_nonpositional</th>\n",
       "      <td>0.738333</td>\n",
       "      <td>0.820370</td>\n",
       "      <td>0.777193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_nonpositional</th>\n",
       "      <td>0.776034</td>\n",
       "      <td>0.848674</td>\n",
       "      <td>0.810730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall        f1\n",
       "exact_subtoken          0.292356  0.790202  0.426805\n",
       "partial_subtoken        0.326332  0.815370  0.466113\n",
       "exact_token             0.299646  0.792924  0.434932\n",
       "partial_token           0.327163  0.813146  0.466595\n",
       "exact_nonpositional     0.738333  0.820370  0.777193\n",
       "partial_nonpositional   0.776034  0.848674  0.810730"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = \"./output/15May2020-14:47:51/checkpoint-162\"\n",
    "ner_system, trainer, vocab = load_model(checkpoint_dir, args_fp=\"./args.yaml\")\n",
    "\n",
    "batches = load_test_data(ner_system, \"./data/dev-ner.json\")\n",
    "\n",
    "predictions = generate_predictions(ner_system, batches)\n",
    "\n",
    "metrics = all_test_metrics(predictions, batches)\n",
    "\n",
    "df = metrics_table(metrics)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val data: 100%|██████████| 543/543 [00:04<00:00, 127.99it/s]\n",
      "Generating predictions: 100%|██████████| 462/462 [00:18<00:00, 24.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exact_subtoken</th>\n",
       "      <td>0.303412</td>\n",
       "      <td>0.791314</td>\n",
       "      <td>0.438638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_subtoken</th>\n",
       "      <td>0.336557</td>\n",
       "      <td>0.815370</td>\n",
       "      <td>0.476451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_token</th>\n",
       "      <td>0.310415</td>\n",
       "      <td>0.794792</td>\n",
       "      <td>0.446460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_token</th>\n",
       "      <td>0.338666</td>\n",
       "      <td>0.815023</td>\n",
       "      <td>0.478501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_nonpositional</th>\n",
       "      <td>0.737896</td>\n",
       "      <td>0.818519</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_nonpositional</th>\n",
       "      <td>0.775714</td>\n",
       "      <td>0.847114</td>\n",
       "      <td>0.809843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall        f1\n",
       "exact_subtoken          0.303412  0.791314  0.438638\n",
       "partial_subtoken        0.336557  0.815370  0.476451\n",
       "exact_token             0.310415  0.794792  0.446460\n",
       "partial_token           0.338666  0.815023  0.478501\n",
       "exact_nonpositional     0.737896  0.818519  0.776119\n",
       "partial_nonpositional   0.775714  0.847114  0.809843"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = \"./output/15May2020-14:47:51/checkpoint-180\"\n",
    "ner_system, trainer, vocab = load_model(checkpoint_dir, args_fp=\"./args.yaml\")\n",
    "\n",
    "batches = load_test_data(ner_system, \"./data/dev-ner.json\")\n",
    "\n",
    "predictions = generate_predictions(ner_system, batches)\n",
    "\n",
    "metrics = all_test_metrics(predictions, batches)\n",
    "\n",
    "df = metrics_table(metrics)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val data: 100%|██████████| 543/543 [00:04<00:00, 134.68it/s]\n",
      "Generating predictions: 100%|██████████| 462/462 [00:18<00:00, 24.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exact_subtoken</th>\n",
       "      <td>0.311462</td>\n",
       "      <td>0.799574</td>\n",
       "      <td>0.448296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_subtoken</th>\n",
       "      <td>0.346472</td>\n",
       "      <td>0.823805</td>\n",
       "      <td>0.487791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_token</th>\n",
       "      <td>0.319370</td>\n",
       "      <td>0.803758</td>\n",
       "      <td>0.457109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_token</th>\n",
       "      <td>0.348292</td>\n",
       "      <td>0.823474</td>\n",
       "      <td>0.489534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_nonpositional</th>\n",
       "      <td>0.730579</td>\n",
       "      <td>0.818519</td>\n",
       "      <td>0.772052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_nonpositional</th>\n",
       "      <td>0.769122</td>\n",
       "      <td>0.847114</td>\n",
       "      <td>0.806236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall        f1\n",
       "exact_subtoken          0.311462  0.799574  0.448296\n",
       "partial_subtoken        0.346472  0.823805  0.487791\n",
       "exact_token             0.319370  0.803758  0.457109\n",
       "partial_token           0.348292  0.823474  0.489534\n",
       "exact_nonpositional     0.730579  0.818519  0.772052\n",
       "partial_nonpositional   0.769122  0.847114  0.806236"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = \"./output/15May2020-14:47:51/checkpoint-198\"\n",
    "ner_system, trainer, vocab = load_model(checkpoint_dir, args_fp=\"./args.yaml\")\n",
    "\n",
    "batches = load_test_data(ner_system, \"./data/dev-ner.json\")\n",
    "\n",
    "predictions = generate_predictions(ner_system, batches)\n",
    "\n",
    "metrics = all_test_metrics(predictions, batches)\n",
    "\n",
    "df = metrics_table(metrics)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val data: 100%|██████████| 543/543 [00:04<00:00, 134.58it/s]\n",
      "Generating predictions: 100%|██████████| 462/462 [00:18<00:00, 24.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exact_subtoken</th>\n",
       "      <td>0.306164</td>\n",
       "      <td>0.802338</td>\n",
       "      <td>0.443205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_subtoken</th>\n",
       "      <td>0.339892</td>\n",
       "      <td>0.825679</td>\n",
       "      <td>0.481552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_token</th>\n",
       "      <td>0.313385</td>\n",
       "      <td>0.804777</td>\n",
       "      <td>0.451106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_token</th>\n",
       "      <td>0.340583</td>\n",
       "      <td>0.823474</td>\n",
       "      <td>0.481868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_nonpositional</th>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.775758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_nonpositional</th>\n",
       "      <td>0.771307</td>\n",
       "      <td>0.847114</td>\n",
       "      <td>0.807435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall        f1\n",
       "exact_subtoken          0.306164  0.802338  0.443205\n",
       "partial_subtoken        0.339892  0.825679  0.481552\n",
       "exact_token             0.313385  0.804777  0.451106\n",
       "partial_token           0.340583  0.823474  0.481868\n",
       "exact_nonpositional     0.735632  0.820513  0.775758\n",
       "partial_nonpositional   0.771307  0.847114  0.807435"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = \"./output/15May2020-14:47:51/checkpoint-216\"\n",
    "ner_system, trainer, vocab = load_model(checkpoint_dir, args_fp=\"./args.yaml\")\n",
    "\n",
    "batches = load_test_data(ner_system, \"./data/dev-ner.json\")\n",
    "\n",
    "predictions = generate_predictions(ner_system, batches)\n",
    "\n",
    "metrics = all_test_metrics(predictions, batches)\n",
    "\n",
    "df = metrics_table(metrics)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformers BART",
   "language": "python",
   "name": "transformers-bart"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
